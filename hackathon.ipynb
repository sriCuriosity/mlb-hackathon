{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9374c47-bc73-4510-92c4-223e60e5f373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 381.7017687615608\n",
      "R-squared: 0.39436409964412955\n",
      "Model saved to: /home/jupyter/homerun_prediction.xgbmodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [13:35:18] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "\n",
    "# Configuration (make these configurable!)\n",
    "PROJECT_ID = \"optimum-time-448801-t4\" # Your Project ID\n",
    "DATASET_ID = \"gcp_hack_dataset\"\n",
    "TABLE_ID = \"cleaned_g2016_mlb_homeruns\"\n",
    "MODEL_FILENAME = \"homerun_prediction.xgbmodel\"\n",
    "MODEL_PATH = os.path.join(os.getcwd(), MODEL_FILENAME) # Or use a cloud storage location\n",
    "\n",
    "def train_and_save_model():\n",
    "    try:\n",
    "        client = bigquery.Client(project=PROJECT_ID)\n",
    "        query = f\"SELECT ExitVelocity, LaunchAngle, HitDistance FROM `{DATASET_ID}.{TABLE_ID}`\"\n",
    "        df = client.query(query).to_dataframe()\n",
    "\n",
    "        X = df[['ExitVelocity', 'LaunchAngle']]\n",
    "        y = df['HitDistance']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Added random_state for reproducibility\n",
    "\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse}\")\n",
    "        print(f\"R-squared: {r2}\")\n",
    "\n",
    "        model.save_model(MODEL_PATH)\n",
    "        print(f\"Model saved to: {MODEL_PATH}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_save_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff9e72c-7da4-4087-b9eb-f256ef6e1906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert to Surprise format\u001b[39;00m\n\u001b[1;32m     13\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader(rating_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfavorite_team_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m trainset, testset \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/surprise/dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[0;34m(cls, df, reader)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_df\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, reader):\n\u001b[1;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m            specified.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetAutoFolds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/surprise/dataset.py:262\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[0;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/surprise/dataset.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from google.cloud import bigquery\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load fan interaction data\n",
    "client = bigquery.Client()\n",
    "query = \"SELECT user_id, favorite_team_id FROM `gcp_hack_dataset.2025-mlb-fan-favs-follows`\"\n",
    "df = client.query(query).to_dataframe()\n",
    "\n",
    "# Convert to Surprise format\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(df[['user_id', 'favorite_team_id']], reader)\n",
    "\n",
    "# Train the model\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(model, open(\"recommendation_model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e527f3c-7efc-4d49-a4d6-0391a622cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery  #Or appropriate library for your chosen method\n",
    "#Import necessary libraries for your chosen recommendation algorithm (surprise, implicit, etc.)\n",
    "\n",
    "#BigQuery Configuration\n",
    "PROJECT_ID = \"optimum-time-448801-t4\"\n",
    "DATASET_ID = \"gcp_hack_dataset\"\n",
    "TABLE_ID = \"your_table_name\"\n",
    "\n",
    "\n",
    "def get_data_from_bigquery():\n",
    "    \"\"\"Retrieves data from BigQuery.\"\"\"\n",
    "    try:\n",
    "        client = bigquery.Client(project=PROJECT_ID)\n",
    "        query = f\"SELECT user_id, favorite_team_id FROM `{DATASET_ID}.{TABLE_ID}`\"\n",
    "        df = client.query(query).to_dataframe()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data from BigQuery: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_and_recommend(df):\n",
    "    \"\"\"Trains the recommendation model and generates recommendations.\"\"\"\n",
    "    #This section depends heavily on your chosen method (surprise, implicit, BigQuery ML, etc.)\n",
    "    #It will involve data preprocessing, model training, and recommendation generation.\n",
    "    #Here's a placeholder:\n",
    "    #... Your recommendation model training and generation logic goes here ...\n",
    "    return recommendations #Return the recommendations in a suitable format\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = get_data_from_bigquery()\n",
    "    if df is not None:\n",
    "        recommendations = train_and_recommend(df)\n",
    "        print(recommendations) #Print the generated recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25577f74-a5e0-48a5-b7ff-6bf4b6e55d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "# Load training data\n",
    "df = pd.read_csv(\"gs://your-bucket-name/game_predictions.csv\")\n",
    "\n",
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Classification Output\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(df.drop('play_outcome', axis=1), df['play_outcome'], epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1f825-0044-4ad6-b776-6b8a14be4093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
